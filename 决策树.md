## **1.决策树**

**熵**
$$
H(D)=\sum_{i}^{n}p_{i}log(\frac{1}{p_{i}})
$$
**信息增益:(选择最大的为根节点)**
$$
g(D|A)=H(D)-H(D|A)
$$
**信息增益比**:
$$
g_{R}(D,A)=\frac{g(D|A)}{H_{A}(D)}
$$
**现阶段在建立决策树时，预剪枝操作是必不可少的，其中涉及的参数也较多，通过大量实验选择合适的参数。后剪枝了解**

**分类任务关注的是类别，可以用熵值表示划分后的混乱程度**，**来选择合适的特征，从根节点开始创建树模型；**

**回归任务关注的是具体的数值，划分后集合方差越小，把同类归纳在一起的可能性越大。以方差为标准选择特征**。

**考虑模型的复杂度，通常利用预剪枝来控制规模。**

## **2. 集成算法**

**bagging       (boostrap aggregating):放回抽样的方法，随机抽样：把多个基础模型（决策树模型）放到一起，最后求平均值。**
$$
f(x)=\frac{1}{M}\sum_{m=1}^{M}f_{m}(x)
$$
**首先对数据进行随机采样，分别训练多个树模型，最后将结果整合在一起**

**随机森林**：**1。数据采样的随机 2。选择不同的特征分别建模 .**

分类任务：求众数 回归任务：直接求平均值。

**boosting算法**

![image-20200304154426547](C:\Users\Dragon.liu\AppData\Roaming\Typora\typora-user-images\image-20200304154426547.png)

![image-20200304154504083](C:\Users\Dragon.liu\AppData\Roaming\Typora\typora-user-images\image-20200304154504083.png)

**Adaboost：最后结果直接加起来**

![image-20200304160408233](C:\Users\Dragon.liu\AppData\Roaming\Typora\typora-user-images\image-20200304160408233.png)

![image-20200304154856427](C:\Users\Dragon.liu\AppData\Roaming\Typora\typora-user-images\image-20200304154856427.png)

**stacking模型**：

**首先选择m个不同分类器分别对数据进行建模，这些分类器可以是各种机器学习算法。再把各个算法的结果当做数据特征传入第二阶段的分类器（只需选择一个）得到最终结果。**

![image-20200304160119432](C:\Users\Dragon.liu\AppData\Roaming\Typora\typora-user-images\image-20200304160119432.png)