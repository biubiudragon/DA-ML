## **降维算法**

**1.线性判别法（Fisher）：**LDA最开始用于处理机器学习的分类任务，但是由于对数据特征进行了降维投影，使其成为一种经典的降维方法。（有监督学习算法）

- 对于不同类别的点，希望其经过投影后能离得越远越好，也就是两类数据点区别越明显越好，不要混在一起。
- 对于同类别的数据点，希望他们能更集中，离组织的中心越近越好。

$$
y=w^Tx
$$

x表示当前数据所在空间，即原始数据，y表示降维后的数据。目标求解出W

**2.主成分分析（PCA）**

## **聚类算法**

### **K-means（无监督）：**

**优点：**

1. 快速、简单很通用
2. 效果不错，可以指定划分的类别数
3. 可解释性强，每一步做了什么都在掌握之中

**缺点：**

1. 在K-means算法中K是事先给定的，是非常难以估计的，很多时候并不会知道所给的数据集应该分成多少个类别才合适。
2. 初始质点的选择有待改进，可能出现不同的结果。
3. 在球形簇上的表现效果非常好，其他类型簇中效果一般

### **DBSCAN聚类算法** ：（异常检测）（无监督问题）

**在无监督问题中遇到检测任务的时候，首选**。**一种基于密度的聚类算法。**

**优点：**

1. .可以对任意形状的稠密数据集进行聚类，而K-means之类的聚类算法一般只适用于秋装数据集。
2. .非常适合检测任务、寻找离群点；
3. 不需要手动指定聚类的堆数。

**缺点：**

1. .如果样本密度不好均匀，聚类间距差相差很大时，聚类效果较差；
2. 半径的选择比较难，不同的半径的结果差异非常大。

DBSCAN算法总体来说是非常实用的，首先不需要指定最终的结果，而且可以用来分析离群点，是检测任务的首选算法。

### **BIRCH算法**

其核心计算方式是增量的，它的计算速度比前面两个都要快。